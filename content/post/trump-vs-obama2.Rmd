---
title: Trump vs Sanders - Finding Middle Ground
slug: trump-vs-sanders2
author: Andrew Marder
date: 2017-10-06
output: pdf_document
twitter:
  card: summary_large_image
  site: "@andrewmarder"
  creator: "@andrewmarder"
  title: Trump vs Sanders - Finding Middle Ground
  description: Using R to identify centrist statements by Donald Trump and Bernie Sanders.
  image: "?"
---

```{r, echo = FALSE}
library(knitr)

opts_chunk$set(warning = FALSE, message = FALSE)
```


## Downloading Data

Link to last week.

```{r}
library(twitteR)
library(tidyverse)

read_tweets <- function() {
    # Connect to the Twitter API
    capture.output(setup_twitter_oauth(
        consumer_key = Sys.getenv("TWITTER_CONSUMER_KEY"),
        consumer_secret = Sys.getenv("TWITTER_CONSUMER_SECRET"),
        access_token = Sys.getenv("TWITTER_ACCESS_TOKEN"),
        access_secret = Sys.getenv("TWITTER_ACCESS_SECRET")
    ))

    # Download tweets by Trump and Sanders
    trump <- userTimeline('realDonaldTrump', n = 3200)
    sanders <- userTimeline('SenSanders', n = 3200)

    # Create a data frame of tweets
    tweets <- bind_rows(twListToDF(trump), twListToDF(sanders))
    return(tweets)
}

raw_tweets <- read_tweets()
```


## Cleaning Data

Set up a table with a row for each word in each tweet (ignoring common
stop words):

```{r}
library(tidytext)

data("stop_words")

options(stringsAsFactors = FALSE)
words_to_ignore <- data.frame(word = c("https", "amp", "t.co"))

words <- raw_tweets %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words, by = "word") %>%
    anti_join(words_to_ignore, by = "word")
```

Let's restrict our analysis to words that appear in at least 1 out of
100 tweets for each author.

```{r}
author_words <- words %>%
    group_by(screenName, word) %>%
    summarise(nword = length(unique(id)))

authors <- raw_tweets %>%
    group_by(screenName) %>%
    summarise(ntweet = length(unique(id)))

author_words <- author_words %>%
    left_join(authors, by = "screenName")

filtered <- author_words %>%
    filter(nword / ntweet >= 0.01) %>%
    group_by(word) %>%
    summarise(nauthors = n()) %>%
    filter(nauthors == 2)
```

There are only `r nrow(filtered)` words that meet this criteria!

```{r}
words <- words %>%
    inner_join(filtered, by = "word")
```


Now let's create a wide data set that has one row for each tweet and a column for each word. We will use this data to see which words best predict authorship.

```{r}
tweets <- words %>%
    group_by(screenName, id, word) %>%
    summarise(contains = 1) %>%
    ungroup() %>%
    spread(key = word, value = contains, fill = 0) %>%
    mutate(tweet_by_trump = as.integer(screenName == "realDonaldTrump")) %>%
    select(-screenName)
```


## Modeling Authorship

I want to build a neural network to predict authorship.

```{r}
library(nnet)

fit <- nnet(
    x = tweets %>% select(-id, -tweet_by_trump) %>% as.matrix(),
    y = tweets$tweet_by_trump,
    size = 2
)

tweets$yhat <- predict(fit)[, 1]

centrist <- tweets %>%
    select(id, yhat) %>%
    mutate(d = abs(yhat - 0.5)) %>%
    arrange(d) %>%
    left_join(raw_tweets %>% select(id, screenName, text), by = "id")

centrist %>%
    select(yhat, screenName, text) %>%
    head(10) %>%
    as.data.frame()
```


## Time Period

It looks like most of Bernie Sanders's tweets are from 2016, while Donald Trump's tweets have been more recent:

```{r}
ggplot(raw_tweets, aes(x = created, y = screenName)) +
    geom_jitter(width = 0) +
    theme_bw() +
    ylab("") +
    xlab("")
```


```{r twitter, fig.height = 3.5, echo = FALSE, fig.show = "hide", dpi = 300}
words %>%
    filter(screenName == "realDonaldTrump") %>%
    count(word) %>%
    with(wordcloud(word, n, max.words = 20))
```
